{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers datasets torch bitsandbytes accelerate\n"
      ],
      "metadata": {
        "id": "oFO0f2whpCcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpi0I7d9pAAu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os, json, torch, itertools\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "BASE_DIR = \"data\"\n",
        "LOGS_DIR = \"logs\"\n",
        "MODEL_DIR_CTR = \"checkpoints\"\n",
        "INPUT_PATH = f\"{BASE_DIR}/verigraph_multistatement_input.jsonl\"\n",
        "CONTRA_CKPT = f\"{MODEL_DIR_CTR}/lora_finetuned/contradiction_model/final_model.pt\"\n",
        "EXPL_CKPT   = f\"{MODEL_DIR_CTR}/lora_finetuned/explanation_model\"\n",
        "OUT_PATH    = f\"{LOGS_DIR}/verigraph_multistatement_outputs.jsonl\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# -------------------- Load Dataset --------------------\n",
        "dataset = load_dataset(\"json\", data_files={\"test\": INPUT_PATH})\n",
        "samples = dataset[\"test\"]\n",
        "print(f\"Loaded {len(samples)} multi-statement samples.\")\n",
        "\n",
        "# -------------------- Load Models --------------------\n",
        "class MiniVeriGraph(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "        self.classifier = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.encoder.config.hidden_size, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 1)\n",
        "        )\n",
        "    def forward(self, input_ids=None, attention_mask=None, **kwargs):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = out.last_hidden_state[:, 0, :]\n",
        "        return torch.sigmoid(self.classifier(pooled)).squeeze(-1)\n",
        "\n",
        "# --- Load contradiction model ---\n",
        "tokenizer_contra = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "contra_model = MiniVeriGraph().to(device)\n",
        "contra_model.load_state_dict(torch.load(CONTRA_CKPT, map_location=device))\n",
        "contra_model.eval()\n",
        "\n",
        "# --- Load explanation model ---\n",
        "tokenizer_exp = AutoTokenizer.from_pretrained(EXPL_CKPT)\n",
        "exp_model = AutoModelForSeq2SeqLM.from_pretrained(EXPL_CKPT).to(device)\n",
        "exp_model.eval()\n",
        "\n",
        "# -------------------- Helper Functions --------------------\n",
        "def detect_contradiction(s1, s2, threshold=0.5):\n",
        "    enc = tokenizer_contra(s1, s2, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        score = contra_model(**enc).item()\n",
        "    label = \"CONTRADICTION\" if score > threshold else \"NON-CONTRADICTION\"\n",
        "    return label, score\n",
        "\n",
        "def generate_explanation(s1, s2):\n",
        "    prompt = f\"Describe how these two statements conflict: '{s1}' vs '{s2}'.\"\n",
        "    enc = tokenizer_exp(prompt, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = exp_model.generate(**enc, max_new_tokens=80)\n",
        "    return tokenizer_exp.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "# -------------------- Run Inference --------------------\n",
        "outputs = []\n",
        "for idx, sample in enumerate(samples):\n",
        "    sents = sample[\"statements\"]\n",
        "    print(f\"\\nSample {idx+1} — {len(sents)} statements\")\n",
        "\n",
        "    for (i, j) in itertools.permutations(range(len(sents)), 2):\n",
        "        s1, s2 = sents[i], sents[j]\n",
        "        label, score = detect_contradiction(s1, s2)\n",
        "        explanation = \"\"\n",
        "\n",
        "        if label == \"CONTRADICTION\":\n",
        "            explanation = generate_explanation(s1, s2)\n",
        "            print(f\"  • {s1} ↔ {s2} → {label} ({score:.2f})\")\n",
        "            print(f\"{explanation}\\n\")\n",
        "        else:\n",
        "            print(f\"  • {s1} ↔ {s2} → {label} ({score:.2f})\")\n",
        "\n",
        "        outputs.append({\n",
        "            \"sample_id\": idx,\n",
        "            \"s1\": s1,\n",
        "            \"s2\": s2,\n",
        "            \"label\": label,\n",
        "            \"score\": round(score, 3),\n",
        "            \"explanation\": explanation\n",
        "        })\n",
        "\n",
        "# -------------------- Save Results --------------------\n",
        "with open(OUT_PATH, \"w\") as f:\n",
        "    for o in outputs:\n",
        "        f.write(json.dumps(o) + \"\\n\")\n",
        "\n",
        "print(f\"\\nInference complete — results saved to:\\n{OUT_PATH}\")\n"
      ]
    }
  ]
}