{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers torch datasets bitsandbytes accelerate\n"
      ],
      "metadata": {
        "id": "pqSatxBqm3Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVg4BUaT-pKC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os, json, torch\n",
        "from torch import nn\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "# -------------------- Paths --------------------\n",
        "BASE_DIR = \"data\"\n",
        "DATA_PATH = f\"{BASE_DIR}/dataset.jsonl\"\n",
        "CKPT_PATH = f\"{BASE_DIR}/checkpoints/final_model_082638.pt\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# -------------------- Load Dataset --------------------\n",
        "dataset = load_dataset(\"json\", data_files={\"test\": DATA_PATH})\n",
        "data = dataset[\"test\"]\n",
        "\n",
        "def prepare_pairs(example):\n",
        "    sents = example[\"statements\"]\n",
        "    pairs = []\n",
        "    for i in range(len(sents)):\n",
        "        for j in range(len(sents)):\n",
        "            if i != j:\n",
        "                pairs.append((sents[i], sents[j]))\n",
        "    return {\"pairs\": pairs}\n",
        "\n",
        "data = data.map(prepare_pairs)\n",
        "pairs = sum(data[\"pairs\"], [])\n",
        "print(f\"Total pairs to test: {len(pairs)}\")\n",
        "\n",
        "# -------------------- Model Definition --------------------\n",
        "class MiniVeriGraph(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.encoder.config.hidden_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, **kwargs):\n",
        "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled = out.last_hidden_state[:, 0, :]\n",
        "        return torch.sigmoid(self.classifier(pooled)).squeeze(-1)\n",
        "\n",
        "# -------------------- Load Checkpoint --------------------\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
        "model = MiniVeriGraph().to(device)\n",
        "model.load_state_dict(torch.load(CKPT_PATH, map_location=device))\n",
        "model.eval()\n",
        "print(f\"Loaded model from: {CKPT_PATH}\")\n",
        "\n",
        "# -------------------- Inference --------------------\n",
        "def predict_contradiction(s1, s2, threshold=0.5):\n",
        "    inputs = tokenizer(s1, s2, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        score = model(**inputs).item()\n",
        "    label = \"CONTRADICTION\" if score > threshold else \"NON-CONTRADICTION\"\n",
        "    return label, score\n",
        "\n",
        "print(\"\\n Example Predictions:\\n\")\n",
        "for idx, (s1, s2) in enumerate(pairs[:15]):\n",
        "    label, score = predict_contradiction(s1, s2)\n",
        "    print(f\"{idx+1:02d}. {s1}\")\n",
        "    print(f\"    â†” {s2}\")\n",
        "    print(f\"Prediction: {label}  (score={score:.2f})\\n\")\n"
      ]
    }
  ]
}